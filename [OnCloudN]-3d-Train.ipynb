{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0dd080c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50b10f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train_ready.csv')\n",
    "img_path = Path('data/train_features/')\n",
    "mask_path = Path('data/train_labels/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65bb81f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chip_id</th>\n",
       "      <th>location</th>\n",
       "      <th>datetime</th>\n",
       "      <th>cloudpath</th>\n",
       "      <th>is_valid</th>\n",
       "      <th>B02_path</th>\n",
       "      <th>B03_path</th>\n",
       "      <th>B04_path</th>\n",
       "      <th>B08_path</th>\n",
       "      <th>label_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adwp</td>\n",
       "      <td>Chifunfu</td>\n",
       "      <td>2020-04-29T08:20:47Z</td>\n",
       "      <td>az://./train_features/adwp</td>\n",
       "      <td>False</td>\n",
       "      <td>data/train_features/adwp/B02.tif</td>\n",
       "      <td>data/train_features/adwp/B03.tif</td>\n",
       "      <td>data/train_features/adwp/B04.tif</td>\n",
       "      <td>data/train_features/adwp/B08.tif</td>\n",
       "      <td>data/train_labels/adwp.tif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  chip_id  location              datetime                   cloudpath  \\\n",
       "0    adwp  Chifunfu  2020-04-29T08:20:47Z  az://./train_features/adwp   \n",
       "\n",
       "   is_valid                          B02_path  \\\n",
       "0     False  data/train_features/adwp/B02.tif   \n",
       "\n",
       "                           B03_path                          B04_path  \\\n",
       "0  data/train_features/adwp/B03.tif  data/train_features/adwp/B04.tif   \n",
       "\n",
       "                           B08_path                  label_path  \n",
       "0  data/train_features/adwp/B08.tif  data/train_labels/adwp.tif  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c42faabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5159139c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_array(chip_folder, band):\n",
    "    chip_folder = Path(chip_folder)\n",
    "    fn = (chip_folder/band).with_suffix('.tif') ## Seems not to work with chip_folder from ColReader\n",
    "    #fn = chip_folder + f'/{band}.tif'\n",
    "    if Path(fn).exists():\n",
    "        return (np.array(Image.open(fn)) / 27000)\n",
    "    else:\n",
    "        return np.zeros((512, 512))\n",
    "\n",
    "def get_4chan(chip_folder):\n",
    "    #ims = get_image_files(fold)\n",
    "    #arrs = ims.map(Image.open).map(np.array)\n",
    "    #stack = (np.stack(arrs, axis = -1) / 16000 * 255).astype(np.uint8)\n",
    "    #assert(stack.shape[-1] == 4)\n",
    "    blue  = get_array(chip_folder, 'B02')\n",
    "    green = get_array(chip_folder, 'B03')\n",
    "    red   = get_array(chip_folder, 'B04')\n",
    "    #infra = get_array(chip_folder, 'B08')\n",
    "    \n",
    "    stack = np.stack([green, red, blue], axis = 0) ## 0\n",
    "    \n",
    "    return PILImage.create((stack*255).astype(np.uint8))# ## stack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9c699f",
   "metadata": {},
   "source": [
    "---\n",
    "## Datasets\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cb86cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask(chip_folder):\n",
    "    fn = (mask_path / chip_folder.name).with_suffix('.tif')\n",
    "    return tensor(np.array(Image.open(fn))).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f79872f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid(chip):\n",
    "    return df.loc[df['chip_id'] == chip.name, 'is_valid'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30e09872",
   "metadata": {},
   "outputs": [],
   "source": [
    "chips = L(img_path.iterdir())\n",
    "valid_chips = chips.argwhere(is_valid)\n",
    "train_chips = chips.argwhere(is_valid, negate = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebdaa0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tfms = [get_4chan]\n",
    "y_tfms = [get_mask]\n",
    "splits = [train_chips, valid_chips]\n",
    "\n",
    "dsets = Datasets(chips, [x_tfms, y_tfms], splits = splits)\n",
    "dls = dsets.dataloaders(bs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97ff0439",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "045ff507",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = CrossEntropyLossFlat(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01b11d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = b[0][0][None,...].to(device='cpu')\n",
    "y = b[1][0][None,...].to(device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9fd408e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b37053f",
   "metadata": {},
   "outputs": [],
   "source": [
    "self = loss\n",
    "inp = y_hat.argmax(dim = self.axis)\n",
    "targ = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dc93213b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 512]) torch.Size([1, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "inp,targ = map(self._contiguous, (inp, targ))\n",
    "print(inp.shape, targ.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e823e4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(isinstance(inp, torch.Tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d4ed2037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(self.floatify and targ.dtype != torch.float16)\n",
    "print(targ.dtype in [torch.int8, torch.int16, torch.int32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f672fd0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "torch.Size([512, 512])\n"
     ]
    }
   ],
   "source": [
    "print(self.flatten and self.is_2d)\n",
    "print(inp.view(-1, inp.shape[-1]).shape)\n",
    "inp = inp.view(-1, inp.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "60ed5476",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-abcf9007dece>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_hat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/fastai/lib/python3.8/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1114\u001b[0m     def __init__(self, weight: Optional[Tensor] = None, size_average=None, ignore_index: int = -100,\n\u001b[1;32m   1115\u001b[0m                  reduce=None, reduction: str = 'mean') -> None:\n\u001b[0;32m-> 1116\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1117\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai/lib/python3.8/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_WeightedLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_Loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_WeightedLoss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weight'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai/lib/python3.8/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_Loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai/lib/python3.8/site-packages/torch/nn/_reduction.py\u001b[0m in \u001b[0;36mlegacy_get_string\u001b[0;34m(size_average, reduce, emit_warning)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mreduce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "R = y_hat.argmax(dim = self.axis).float().flatten()\n",
    "S = y.flatten()\n",
    "nn.CrossEntropyLoss(R,S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "90b034af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/karrrrrrrr/miniconda3/envs/fastai/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m(2824)\u001b[0;36mcross_entropy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   2822 \u001b[0;31m    \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   2823 \u001b[0;31m        \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 2824 \u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   2825 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   2826 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> input.type()\n",
      "'torch.LongTensor'\n",
      "ipdb> target.type()\n",
      "'torch.FloatTensor'\n",
      "ipdb> q\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074953dc",
   "metadata": {},
   "source": [
    "---\n",
    "## End Datasets\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88f55a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class EmptyBlock(TransformBlock):\n",
    "#    def __init__(self, type_tfms=None, item_tfms=None, batch_tfms=None, dl_type=None, dls_kwargs=None):\n",
    "#        super().__init__(type_tfms=type_tfms, item_tfms=item_tfms, batch_tfms=batch_tfms, dl_type=dl_type, dls_kwargs=dls_kwargs)\n",
    "#        self.item_tfms = L(item_tfms)\n",
    "#        \n",
    "#Simple4Chan = EmptyBlock(type_tfms = get_4chan)\n",
    "#FourChanImageBlock = TransformBlock(type_tfms = get_4chan, batch_tfms = IntToFloatTensor)\n",
    "#\n",
    "#db = DataBlock(\n",
    "#    blocks = (FourChanImageBlock, MaskBlock),\n",
    "#    get_x = ColReader('chip_id', pref = img_path),\n",
    "#    get_y = ColReader('label_path'),\n",
    "#    splitter = ColSplitter(),\n",
    "#    #item_tfms = Resize(IMG_SIZE),\n",
    "#    #batch_tfms = setup_aug_tfms([#Rotate(), \n",
    "#    #                             RandomResizedCropGPU(IMG_SIZE, min_scale = 0.3), \n",
    "#    #                             #Brightness(0.3), \n",
    "#    #                             #Contrast(0.3), \n",
    "#    #                             #Hue(), \n",
    "#    #                             #Saturation(0.3)\n",
    "#    #                           ])\n",
    "#)\n",
    "#\n",
    "#dls = db.dataloaders(df, bs = 3)\n",
    "#\n",
    "#dls.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e378ec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = dls.one_batch()[0].shape[-2:]\n",
    "\n",
    "model = create_unet_model(\n",
    "    arch = resnet34,\n",
    "    n_out = 2,\n",
    "    img_size = img_size,\n",
    ")\n",
    "\n",
    "_default_meta    = {'cut':None, 'split':default_split}\n",
    "meta = model_meta.get(resnet34, _default_meta)\n",
    "\n",
    "learn = Learner(\n",
    "    dls,\n",
    "    model,\n",
    "    loss_func = CrossEntropyLossFlat(axis = 1),\n",
    "    metrics = [Dice, JaccardCoeff],\n",
    "    splitter = meta['split']\n",
    ")\n",
    "\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ff7334",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f101c1a6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5ff260",
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50308578",
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.fine_tune(5, 4e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6407c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#result_metric = None\n",
    "#learn.export(f'res34_{IMG_SIZE}_j{result_metric}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

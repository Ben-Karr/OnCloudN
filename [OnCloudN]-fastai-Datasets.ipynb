{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0dd080c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "from albumentations import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50b10f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('data')\n",
    "TRAIN_PATH = DATA_PATH / 'train_features'\n",
    "LABEL_PATH = DATA_PATH / 'train_labels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c78f441",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_PATH / 'train_ready.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65bb81f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chip_id</th>\n",
       "      <th>location</th>\n",
       "      <th>datetime</th>\n",
       "      <th>cloudpath</th>\n",
       "      <th>is_valid</th>\n",
       "      <th>B02_path</th>\n",
       "      <th>B03_path</th>\n",
       "      <th>B04_path</th>\n",
       "      <th>B08_path</th>\n",
       "      <th>label_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adwp</td>\n",
       "      <td>Chifunfu</td>\n",
       "      <td>2020-04-29T08:20:47Z</td>\n",
       "      <td>az://./train_features/adwp</td>\n",
       "      <td>False</td>\n",
       "      <td>data/train_features/adwp/B02.tif</td>\n",
       "      <td>data/train_features/adwp/B03.tif</td>\n",
       "      <td>data/train_features/adwp/B04.tif</td>\n",
       "      <td>data/train_features/adwp/B08.tif</td>\n",
       "      <td>data/train_labels/adwp.tif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  chip_id  location              datetime                   cloudpath  \\\n",
       "0    adwp  Chifunfu  2020-04-29T08:20:47Z  az://./train_features/adwp   \n",
       "\n",
       "   is_valid                          B02_path  \\\n",
       "0     False  data/train_features/adwp/B02.tif   \n",
       "\n",
       "                           B03_path                          B04_path  \\\n",
       "0  data/train_features/adwp/B03.tif  data/train_features/adwp/B04.tif   \n",
       "\n",
       "                           B08_path                  label_path  \n",
       "0  data/train_features/adwp/B08.tif  data/train_labels/adwp.tif  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c42faabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 512\n",
    "BS = 2\n",
    "DEBUG = None ## Size of development set or None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5159139c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_array(chip, band):\n",
    "    fn = (TRAIN_PATH / chip /band).with_suffix('.tif')\n",
    "    if fn.exists():\n",
    "        return (np.array(Image.open(fn)) / 27000)\n",
    "    else:\n",
    "        return np.zeros((512, 512))\n",
    "\n",
    "def get_4chan_plain(chip_folder):\n",
    "    blue  = get_array(chip_folder, 'B02')\n",
    "    green = get_array(chip_folder, 'B03')\n",
    "    red   = get_array(chip_folder, 'B04')\n",
    "    infra = get_array(chip_folder, 'B08')\n",
    "    stack = np.stack([blue, green, red, infra], axis = 0)#.astype(np.uint8)\n",
    "    return TensorImage(stack)#tensor(stack).float()\n",
    "\n",
    "def get_4chan(chip_folder):\n",
    "    blue  = get_array(chip_folder, 'B02')\n",
    "    green = get_array(chip_folder, 'B03')\n",
    "    red   = get_array(chip_folder, 'B04')\n",
    "    infra = get_array(chip_folder, 'B08')   \n",
    "    stack = np.stack([blue, green, red, infra], axis = 0) \n",
    "    return stack\n",
    "\n",
    "def get_mask_plain(chip):\n",
    "    fn = (LABEL_PATH / chip).with_suffix('.tif')\n",
    "    return TensorMask(Image.open(fn))#tensor(np.array(Image.open(fn))).long()\n",
    "\n",
    "def get_mask(chip):\n",
    "    fn = (LABEL_PATH / chip).with_suffix('.tif')\n",
    "    return np.array(Image.open(fn))\n",
    "\n",
    "def get_chips(path):\n",
    "    potential_chips = list(path.iterdir())\n",
    "    chips_paths = L(chip for chip in potential_chips if chip.is_dir())\n",
    "    return chips_paths.attrgot('name')\n",
    "\n",
    "def is_valid(chip):\n",
    "    return df.loc[df['chip_id'] == chip, 'is_valid'].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9c699f",
   "metadata": {},
   "source": [
    "---\n",
    "## <Datasets\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "039c9437",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chips:\n",
    "    def __init__(self, src_path, df_path, debug = None):\n",
    "        self.src_path = src_path\n",
    "        self.debug = debug\n",
    "        self.names = self._get_chips(src_path)\n",
    "        self.df = pd.read_csv(df_path)\n",
    "        self.train_idx = self.names.argwhere(self._is_valid, negate = True)\n",
    "        self.valid_idx = self.names.argwhere(self._is_valid)\n",
    "        assert(len(self.train_idx) + len(self.valid_idx) == len(self.names))\n",
    "        assert(len(set(self.train_idx).intersection(set(self.valid_idx))) == 0)\n",
    "    \n",
    "    def _is_valid(self, chip):\n",
    "        return self.df.loc[self.df['chip_id'] == chip, 'is_valid'].item()\n",
    "    \n",
    "    def _get_chips(self, path):\n",
    "        potential_chips = list(path.iterdir())\n",
    "        chips_paths = [chip for chip in potential_chips if chip.is_dir()]\n",
    "        if self.debug:\n",
    "            chips_paths = random.choices(chips_paths, k = self.debug)\n",
    "        return L(chips_paths).attrgot('name')\n",
    "    \n",
    "    def describe(self):\n",
    "        print(f'Number of validation items: {len(self.valid_idx)}, number of training items: {len(self.train_idx)}\\nTotal number of items: {len(self.names)}')\n",
    "        \n",
    "    def get_train_chips(self):\n",
    "        return self.names[self.train_idx]\n",
    "    \n",
    "    def get_valid_chips(self):\n",
    "        return self.names[self.valid_idx]\n",
    "    \n",
    "    def get_splits(self):\n",
    "        return [self.train_idx, self.valid_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79f31466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of validation items: 2442, number of training items: 9306\n",
      "Total number of items: 11748\n"
     ]
    }
   ],
   "source": [
    "chips = Chips(TRAIN_PATH, DATA_PATH / 'train_ready.csv', debug = DEBUG)\n",
    "chips.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f58196e4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plain_dsets = Datasets(chips.names, ([get_4chan_plain], [get_mask_plain]), splits = chips.get_splits())\n",
    "tfms_dsets = Datasets(chips.names, [[get_4chan], [get_mask]], splits = chips.get_splits())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4f5563",
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(plain_dsets)\n",
    "print((next(it)[0] == plain_dsets[0][0]).all())\n",
    "print((next(it)[0] == plain_dsets[1][0]).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074953dc",
   "metadata": {},
   "source": [
    "---\n",
    "## Datasets>\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d6360f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((plain_dsets[0][0] == get_4chan_plain(chips.names[0])).all())\n",
    "print((plain_dsets[0][1] == get_mask_plain(chips.names[0])) .all())\n",
    "\n",
    "print((tfms_dsets[0][0] == get_4chan(chips.names[0])).all())\n",
    "print((tfms_dsets[0][1] == get_mask(chips.names[0])) .all())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84ff8cf",
   "metadata": {},
   "source": [
    "---\n",
    "## < Transforms\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbba38b",
   "metadata": {},
   "source": [
    "### Plain/no tfms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab4039bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_dls = plain_dsets.dataloaders(\n",
    "    bs = BS, \n",
    "    num_workers = 6, \n",
    "    pin_memory = True,\n",
    "    #after_item = [ToTensor],\n",
    "    #after_batch = [IntToFloatTensor, RandomResizedCropGPU(440)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144a65f3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plain_b = plain_dls.one_batch()\n",
    "plain_xb = plain_b[0]\n",
    "plain_yb = plain_b[1]\n",
    "print(plain_xb.shape, plain_yb.shape)\n",
    "print(plain_xb.type(), plain_yb.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648f87ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import _MultiProcessingDataLoaderIter,_SingleProcessDataLoaderIter,_DatasetKind\n",
    "_loaders = (_MultiProcessingDataLoaderIter,_SingleProcessDataLoaderIter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0cc30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_workers = plain_dls.fake_l.num_workers\n",
    "print(n_workers == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa830f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "faky = _MultiProcessingDataLoaderIter(plain_dls.fake_l)\n",
    "for b in faky:\n",
    "    print(type(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca9562a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(plain_dls.loaders[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0274181d",
   "metadata": {},
   "source": [
    "### Returns:\n",
    "* `before_batch` returns list of single tuples (img, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2732872",
   "metadata": {},
   "outputs": [],
   "source": [
    "@Transform\n",
    "def print_after_item(x):\n",
    "    print(f'At after_item: {type(x)}')\n",
    "    if type(x) in [np.ndarray, torch.Tensor]:\n",
    "        print(x.shape)\n",
    "    elif type(x) == list:\n",
    "        print(len(x))\n",
    "    return x\n",
    "\n",
    "@Transform\n",
    "def print_before_batch(x):\n",
    "    print(f'At before_batch: {type(x)}')\n",
    "    if type(x) in [np.ndarray, torch.Tensor]:\n",
    "        print(x.shape)\n",
    "    elif type(x) in [list, tuple]:\n",
    "        print(len(x))\n",
    "    return x\n",
    "\n",
    "@Transform\n",
    "def print_after_batch(x):\n",
    "    x\n",
    "    print(f'At after_batch: {type(x)}')\n",
    "    if type(x) in [np.ndarray, torch.Tensor]:\n",
    "        print(x.shape)\n",
    "    elif type(x) == list:\n",
    "        print(len(x))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce131ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f06cbb6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if state:\n",
    "    print('Use tfms:')\n",
    "    tfms_dls = tfms_dsets.dataloaders(\n",
    "        bs = BS, \n",
    "        num_workers = 6, \n",
    "        pin_memory = True, \n",
    "        # x = (x_0,…,x_bs) | y = (y_0,…,y_bs) | b = ((x_0,y_0),…,(x_bs,y_bs))\n",
    "        after_item = [print_after_item], ## Applied to all x_i, y_i indiv. for all i's\n",
    "        before_batch = [print_before_batch], ## Applied to [(x_0, y_0),…,(x_bs,y_bs)]\n",
    "        ## Is turned from np.array to tensor\n",
    "        after_batch = [print_after_batch] ## Applied to [x, y]\n",
    "    )\n",
    "else:\n",
    "    print(\"Don't use tfms\")\n",
    "    tfms_dls = tfms_dsets.dataloaders(bs = BS, num_workers = 6, pin_memory = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a2cf58",
   "metadata": {},
   "source": [
    "### With tfms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed51c0b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tfms_b = tfms_dls.one_batch()\n",
    "tfms_xb = tfms_b[0]\n",
    "tfms_yb = tfms_b[1]\n",
    "print('\\nPrint shapes and types:')\n",
    "print(tfms_xb.shape, tfms_yb.shape)\n",
    "print(tfms_xb.type(), tfms_yb.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baab0cb6",
   "metadata": {},
   "source": [
    "### -------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc09fa4",
   "metadata": {},
   "source": [
    "### Compare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6832356e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_x = plain_xb[0]\n",
    "tfms_x = tfms_xb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0caa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_x[0,:5,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f1690c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms_x[0,-5:,-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0468f323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_visual(img, ax = None):\n",
    "    img = img.cpu()[:3,...].numpy().transpose(1,2,0)\n",
    "    if ax == None:\n",
    "        _, ax = plt.subplots(1)\n",
    "    ax.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4b7cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_visual(plain_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9241c1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def show_with_mask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b1aa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_seg_batch(b):\n",
    "    imgb, maskb = b\n",
    "    bs = imgb.shape[0]\n",
    "    print(bs)\n",
    "    \n",
    "    fig, axs = plt.subplots(bs, 3, figsize = (20, 15))\n",
    "    for i in range(bs):\n",
    "        axs[i][0].imshow(imgs[i])\n",
    "        axs[i][1].imshow(masks[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6faffd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "b[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a552304",
   "metadata": {},
   "source": [
    "---\n",
    "## Transforms >\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed63e766",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = plain_dls\n",
    "\n",
    "class BananaLoss(CrossEntropyLossFlat):\n",
    "    def __call__(self, inp, targ, **kwargs):\n",
    "        inp,targ  = map(self._contiguous, (inp,targ))\n",
    "        targ = targ.long()\n",
    "        if self.floatify and targ.dtype!=torch.float16: targ = targ.float()\n",
    "        if targ.dtype in [torch.int8, torch.int16, torch.int32]: targ = targ.long()\n",
    "        if self.flatten: inp = inp.view(-1,inp.shape[-1]) if self.is_2d else inp.view(-1)\n",
    "        return self.func.__call__(inp, targ.view(-1) if self.flatten else targ, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e378ec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels, *img_size = dls.one_batch()[0].shape[-3:]\n",
    "\n",
    "model = create_unet_model(\n",
    "    arch = resnet34,\n",
    "    n_out = 2,\n",
    "    img_size = img_size,\n",
    "    n_in = n_channels\n",
    ")\n",
    "\n",
    "_default_meta    = {'cut':None, 'split':default_split}\n",
    "meta = model_meta.get(resnet34, _default_meta)\n",
    "\n",
    "learn = Learner(\n",
    "    dls,\n",
    "    model,\n",
    "    loss_func = BananaLoss(axis = 1),\n",
    "    metrics = [Dice, JaccardCoeff],\n",
    "    splitter = meta['split']\n",
    ")\n",
    "\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ff7334",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f101c1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7c9f9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.6 ms ± 1.17 ms per loop (mean ± std. dev. of 10 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r 10 -n 10 dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f462a901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>dice</th>\n",
       "      <th>jaccard_coeff</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.248852</td>\n",
       "      <td>0.195848</td>\n",
       "      <td>0.936604</td>\n",
       "      <td>0.880767</td>\n",
       "      <td>22:29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be89473c",
   "metadata": {},
   "source": [
    "# Time overview:\n",
    "* without tfms: 22:30 min | __baseline__\n",
    "* with flip transforms: 8:15min | but something is wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50308578",
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.fine_tune(5, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6407c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#result_metric = None\n",
    "#learn.export(f'res34_{IMG_SIZE}_j{905}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

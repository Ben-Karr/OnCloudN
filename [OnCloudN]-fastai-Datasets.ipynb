{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0dd080c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "from albumentations import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50b10f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('data')\n",
    "TRAIN_PATH = DATA_PATH / 'train_features'\n",
    "LABEL_PATH = DATA_PATH / 'train_labels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c78f441",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_PATH / 'train_ready.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65bb81f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chip_id</th>\n",
       "      <th>location</th>\n",
       "      <th>datetime</th>\n",
       "      <th>cloudpath</th>\n",
       "      <th>is_valid</th>\n",
       "      <th>B02_path</th>\n",
       "      <th>B03_path</th>\n",
       "      <th>B04_path</th>\n",
       "      <th>B08_path</th>\n",
       "      <th>label_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adwp</td>\n",
       "      <td>Chifunfu</td>\n",
       "      <td>2020-04-29T08:20:47Z</td>\n",
       "      <td>az://./train_features/adwp</td>\n",
       "      <td>False</td>\n",
       "      <td>data/train_features/adwp/B02.tif</td>\n",
       "      <td>data/train_features/adwp/B03.tif</td>\n",
       "      <td>data/train_features/adwp/B04.tif</td>\n",
       "      <td>data/train_features/adwp/B08.tif</td>\n",
       "      <td>data/train_labels/adwp.tif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  chip_id  location              datetime                   cloudpath  \\\n",
       "0    adwp  Chifunfu  2020-04-29T08:20:47Z  az://./train_features/adwp   \n",
       "\n",
       "   is_valid                          B02_path  \\\n",
       "0     False  data/train_features/adwp/B02.tif   \n",
       "\n",
       "                           B03_path                          B04_path  \\\n",
       "0  data/train_features/adwp/B03.tif  data/train_features/adwp/B04.tif   \n",
       "\n",
       "                           B08_path                  label_path  \n",
       "0  data/train_features/adwp/B08.tif  data/train_labels/adwp.tif  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c42faabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 512\n",
    "BS = 2\n",
    "DEBUG = BS * 200 ## Size of development set or None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5159139c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multiband_img(chip_path):\n",
    "    blue  = get_array(chip_path, 'B02')\n",
    "    green = get_array(chip_path, 'B03')\n",
    "    red   = get_array(chip_path, 'B04')\n",
    "    infra = get_array(chip_path, 'B08')   \n",
    "    stack = np.stack([blue, green, red, infra], axis = -1)##resulting size:(width,height,bands)\n",
    "    return stack\n",
    "\n",
    "def get_array(chip_path, band):\n",
    "    fn = (chip_path / band).with_suffix('.tif')\n",
    "    if fn.exists():\n",
    "        return (np.array(Image.open(fn)) / 27000)\n",
    "    else:\n",
    "        return np.zeros((512, 512))\n",
    "\n",
    "def get_mask(chip_path):\n",
    "    fn = (LABEL_PATH / chip_path.stem).with_suffix('.tif')\n",
    "    return np.array(Image.open(fn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "039c9437",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chips:\n",
    "    def __init__(self, src_path, df_src, debug = None):\n",
    "        self.src_path = src_path\n",
    "        self.df = self._get_df(df_src)\n",
    "        self.paths = self._get_paths(debug)\n",
    "       \n",
    "    def _is_valid(self, chip):\n",
    "        return self.df.loc[self.df['chip_id'] == chip.stem, 'is_valid'].item()\n",
    "    \n",
    "    def _get_paths(self, debug):\n",
    "        if debug:\n",
    "            self.df = self.df.sample(n=debug)\n",
    "        chips = self.df['chip_id'].tolist()\n",
    "        return L([self.src_path / chip for chip in chips])\n",
    "    \n",
    "    def _get_df(self, src):\n",
    "        if isinstance(src, pd.DataFrame):\n",
    "            return src\n",
    "        elif isinstance(src, (Path, str)):\n",
    "            return pd.read_csv(src)\n",
    "        else:\n",
    "            print('Can not load dataframe, should be pd.DataFrame or path to .csv')\n",
    "        \n",
    "    def get_paths(self):\n",
    "        return self.names.map(lambda x: (self.src_path / x))\n",
    "    \n",
    "    def get_train_chips(self):\n",
    "        self.train_idx = self.paths.argwhere(self._is_valid, negate = True)\n",
    "        return self.paths[self.train_idx]\n",
    "    \n",
    "    def get_valid_chips(self):\n",
    "        self.valid_idx = self.paths.argwhere(self._is_valid)\n",
    "        return self.paths[self.valid_idx]\n",
    "    \n",
    "    def get_splits(self):\n",
    "        if not hasattr(self, 'train_idx'):\n",
    "            self.train_idx = self.paths.argwhere(self._is_valid, negate = True)\n",
    "        if not hasattr(self, 'valid_idx'):\n",
    "            self.valid_idx = self.paths.argwhere(self._is_valid)\n",
    "        return [self.train_idx, self.valid_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f58196e4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "chips = Chips(TRAIN_PATH, df, debug = DEBUG)\n",
    "dsets = Datasets(chips.paths, ([get_multiband_img], [get_mask]), splits = chips.get_splits())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9372c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationAlbumentationsTransform(ItemTransform):\n",
    "    split_idx = 0\n",
    "    def __init__(self, aug): \n",
    "        self.aug = aug\n",
    "    def encodes(self, x):\n",
    "        augs = []\n",
    "        for img,mask in x:\n",
    "            augs.append(tuple(self.aug(image=img, mask=mask).values()))\n",
    "        return augs\n",
    "    \n",
    "class TransposeTransform(ItemTransform):\n",
    "    def encodes(self, x):\n",
    "        transposed = []\n",
    "        for img, mask in x:\n",
    "            transposed.append((TensorImage(img.transpose(2,0,1)).float(), TensorMask(mask).long()))\n",
    "        return transposed\n",
    "    \n",
    "class FormatTransform(ItemTransform):\n",
    "    def __init__(self, return_type):\n",
    "        self.return_type = return_type\n",
    "    \n",
    "    def encodes(self, x):\n",
    "        #if isinstance(x, torch.Tensor):\n",
    "            #return TensorImage(x.permute(0,3,1,2)).float()\n",
    "        return self.return_type([TensorImage(x[0].permute(0,3,1,2)).float(), TensorMask(x[1]).long()])\n",
    "        #return self.return_type([TensorImage(x[0]).float(), TensorMask(x[1]).long()])\n",
    "\n",
    "augs_list = A.Compose([\n",
    "     A.Flip(),\n",
    "     #A.RandomCrop(440, 440),\n",
    "     A.CoarseDropout()\n",
    "    ])\n",
    "\n",
    "aug_tfms = SegmentationAlbumentationsTransform(augs_list)\n",
    "transpose_tfm = TransposeTransform()\n",
    "format_tfm = FormatTransform(tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab4039bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dsets.dataloaders(\n",
    "    bs = BS, \n",
    "    num_workers = 6, \n",
    "    pin_memory = True,\n",
    "    device = 'cuda',\n",
    "    #after_item = [],\n",
    "    before_batch = [aug_tfms, transpose_tfm],\n",
    "    #after_batch = [format_tfm],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e378ec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels, *img_size = dls.one_batch()[0].shape[-3:]\n",
    "\n",
    "model = create_unet_model(\n",
    "    arch = resnet34,\n",
    "    n_out = 2,\n",
    "    img_size = img_size,\n",
    "    n_in = n_channels\n",
    ")\n",
    "\n",
    "_default_meta    = {'cut':None, 'split':default_split}\n",
    "meta = model_meta.get(resnet34, _default_meta)\n",
    "\n",
    "learn = Learner(\n",
    "    dls,\n",
    "    model,\n",
    "    loss_func = CrossEntropyLossFlat(axis = 1),##model returns pred w/ shape (2,w,h) where 1st axis holds (p,1-p)\n",
    "    metrics = [Dice, JaccardCoeff],\n",
    "    splitter = meta['split']\n",
    ")\n",
    "\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ff7334",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f101c1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f462a901",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>dice</th>\n",
       "      <th>jaccard_coeff</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.469546</td>\n",
       "      <td>0.409175</td>\n",
       "      <td>0.843298</td>\n",
       "      <td>0.729054</td>\n",
       "      <td>01:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>dice</th>\n",
       "      <th>jaccard_coeff</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.349062</td>\n",
       "      <td>0.304411</td>\n",
       "      <td>0.877750</td>\n",
       "      <td>0.782133</td>\n",
       "      <td>01:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fine_tune(1, 1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31ef7a1",
   "metadata": {},
   "source": [
    "### Tests for tfms speed:\n",
    "\n",
    "|tfms|bs|No. imgs|time frozen|time unfrozen|\n",
    "|----|--|--------|-----------|-------------|\n",
    "|standard|2|600|01:05|01:07|\n",
    "|w/o augs|2|600|01:09|01:12|\n",
    "|w/ crop|2|600|00:51|00:52|\n",
    "|w/ dropout|2|600|01:04|01:06|\n",
    "|perm @np|2|600|00:49|00:49|\n",
    "|@np dropout|2|600|00:47|00:47|\n",
    "|@np dropout|3|600|01:14|01:13|\n",
    "\n",
    "|tfms|bs|No. imgs|time frozen|time unfrozen|\n",
    "|:----|--|--------|-----------|-------------|\n",
    "|@ batch|||01:07|01:09|\n",
    "|@ list|||00:49|00:49|\n",
    "|@ loading|2||00:48|00:48|\n",
    "|@ loading|3||01:14|01:14|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d1955b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.export(f'res34_{IMG_SIZE}_j{881}_v5')\n",
    "#learn.export('test_debug_v6')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
